[2023-12-13 12:29:21,523][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 12:29:22,167][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 12:29:23,200][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 12:29:23,640][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 12:29:23,642][main][INFO] - model: AudioVideoModel
[2023-12-13 12:29:23,642][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 12:29:23,644][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 12:29:23,645][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 12:29:23,645][dataset][INFO] - Using tokenizer
[2023-12-13 12:29:23,789][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 12:29:23,790][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f78118672e0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 12:29:23,799][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 12:29:23,800][dataset][INFO] - Using tokenizer
[2023-12-13 12:29:23,803][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 12:29:23,803][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f7811863df0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 12:29:23,805][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 12:29:24,660][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 12:29:24,660][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 12:29:24,660][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 12:29:24,660][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 12:29:24,660][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 12:29:24,660][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 12:29:24,660][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 12:48:30,191][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 12:48:30,793][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 12:48:31,830][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 12:48:32,262][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 12:48:32,264][main][INFO] - model: AudioVideoModel
[2023-12-13 12:48:32,265][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 12:48:32,266][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 12:48:32,267][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 12:48:32,267][dataset][INFO] - Using tokenizer
[2023-12-13 12:48:32,415][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 12:48:32,416][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f0215667460>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 12:48:32,425][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 12:48:32,426][dataset][INFO] - Using tokenizer
[2023-12-13 12:48:32,429][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 12:48:32,430][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f0215663b50>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 12:48:32,431][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 12:48:32,718][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 12:48:32,718][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 12:48:32,718][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 12:48:32,718][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 12:48:32,718][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 12:48:32,718][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 12:48:32,718][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 12:56:44,824][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 12:56:45,499][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 12:56:46,520][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 12:56:46,968][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 12:56:46,970][main][INFO] - model: AudioVideoModel
[2023-12-13 12:56:46,970][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 12:56:46,972][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 12:56:46,973][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 12:56:46,973][dataset][INFO] - Using tokenizer
[2023-12-13 12:56:47,141][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 12:56:47,142][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f61e3666250>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 12:56:47,152][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 12:56:47,152][dataset][INFO] - Using tokenizer
[2023-12-13 12:56:47,156][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 12:56:47,156][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f61e3663e80>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 12:56:47,157][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 12:56:47,692][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 12:56:47,692][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 12:56:47,692][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 12:56:47,692][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 12:56:47,692][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 12:56:47,693][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 12:56:47,693][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 12:59:35,855][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 12:59:36,625][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 12:59:37,794][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 12:59:38,412][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 12:59:38,417][main][INFO] - model: AudioVideoModel
[2023-12-13 12:59:38,417][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 12:59:38,428][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 12:59:38,437][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 12:59:38,437][dataset][INFO] - Using tokenizer
[2023-12-13 12:59:38,583][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 12:59:38,584][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f44bb947280>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 12:59:38,601][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 12:59:38,601][dataset][INFO] - Using tokenizer
[2023-12-13 12:59:38,606][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 12:59:38,606][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f44bb943ca0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 12:59:38,610][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 12:59:38,937][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 12:59:38,938][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 12:59:38,938][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 12:59:38,938][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 12:59:38,938][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 12:59:38,940][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 12:59:38,940][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:00:26,321][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:00:27,085][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:00:28,153][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:00:28,664][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:00:28,669][main][INFO] - model: AudioVideoModel
[2023-12-13 13:00:28,669][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:00:28,680][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:00:28,688][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:00:28,689][dataset][INFO] - Using tokenizer
[2023-12-13 13:00:28,838][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:00:28,839][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f4f94f4b370>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:00:28,855][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:00:28,855][dataset][INFO] - Using tokenizer
[2023-12-13 13:00:28,860][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:00:28,860][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f4f94f47e80>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:00:28,864][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:00:29,225][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:00:29,225][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:00:29,225][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:00:29,225][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:00:29,226][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:00:29,227][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:00:29,227][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:01:29,801][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:01:30,565][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:01:31,627][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:01:32,139][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:01:32,144][main][INFO] - model: AudioVideoModel
[2023-12-13 13:01:32,144][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:01:32,155][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:01:32,163][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:01:32,163][dataset][INFO] - Using tokenizer
[2023-12-13 13:01:32,306][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:01:32,307][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f62ff34b4f0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:01:32,323][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:01:32,323][dataset][INFO] - Using tokenizer
[2023-12-13 13:01:32,329][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:01:32,329][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f62ff347970>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:01:32,333][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:01:32,687][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:01:32,687][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:01:32,687][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:01:32,687][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:01:32,688][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:01:32,689][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:01:32,689][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:02:52,157][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:02:52,942][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:02:54,130][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:02:54,647][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:02:54,652][main][INFO] - model: AudioVideoModel
[2023-12-13 13:02:54,652][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:02:54,663][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:02:54,671][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:02:54,672][dataset][INFO] - Using tokenizer
[2023-12-13 13:02:54,814][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:02:54,815][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f064190b640>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:02:54,830][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:02:54,831][dataset][INFO] - Using tokenizer
[2023-12-13 13:02:54,836][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:02:54,836][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f06419070a0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:02:54,840][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:02:55,553][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:02:55,553][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:02:55,554][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:02:55,554][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:02:55,554][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:02:55,555][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:02:55,555][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:15:39,510][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:15:40,263][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:15:41,353][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:15:41,934][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:15:41,940][main][INFO] - model: AudioVideoModel
[2023-12-13 13:15:41,941][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:15:41,954][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:15:41,963][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:15:41,964][dataset][INFO] - Using tokenizer
[2023-12-13 13:15:42,141][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:15:42,143][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f59e274b550>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:15:42,161][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:15:42,161][dataset][INFO] - Using tokenizer
[2023-12-13 13:15:42,167][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:15:42,168][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f59e27479d0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:15:42,172][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:15:42,960][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:15:42,960][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:15:42,960][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:15:42,960][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:15:42,960][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:15:42,961][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:15:42,962][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:16:57,333][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:16:58,089][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:16:59,183][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:16:59,688][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:16:59,694][main][INFO] - model: AudioVideoModel
[2023-12-13 13:16:59,694][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:16:59,706][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:16:59,714][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:16:59,714][dataset][INFO] - Using tokenizer
[2023-12-13 13:16:59,882][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:16:59,883][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7fda3414b490>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:16:59,899][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:16:59,900][dataset][INFO] - Using tokenizer
[2023-12-13 13:16:59,905][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:16:59,905][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7fda34147c10>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:16:59,909][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:17:00,747][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:17:00,747][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:17:00,747][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:17:00,748][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:17:00,748][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:17:00,750][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:17:00,750][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:18:03,836][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:18:04,608][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:18:05,680][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:18:06,182][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:18:06,187][main][INFO] - model: AudioVideoModel
[2023-12-13 13:18:06,187][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:18:06,198][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:18:06,206][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:18:06,207][dataset][INFO] - Using tokenizer
[2023-12-13 13:18:06,372][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:18:06,373][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f233274b580>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:18:06,389][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:18:06,390][dataset][INFO] - Using tokenizer
[2023-12-13 13:18:06,395][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:18:06,395][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f2332748a00>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:18:06,399][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:18:06,733][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:18:06,733][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:18:06,733][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:18:06,734][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:18:06,734][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:18:06,735][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:18:06,735][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:20:33,867][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:20:34,646][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:20:35,711][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:20:36,228][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:20:36,233][main][INFO] - model: AudioVideoModel
[2023-12-13 13:20:36,234][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:20:36,245][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:20:36,253][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:20:36,253][dataset][INFO] - Using tokenizer
[2023-12-13 13:20:36,405][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:20:36,406][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f0031883580>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:20:36,422][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:20:36,422][dataset][INFO] - Using tokenizer
[2023-12-13 13:20:36,427][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:20:36,427][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f003192ca00>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:20:36,431][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:20:36,748][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:20:36,748][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:20:36,748][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:20:36,748][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:20:36,748][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:20:36,749][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:20:36,750][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:21:19,396][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:21:20,155][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:21:21,240][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:21:21,752][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:21:21,757][main][INFO] - model: AudioVideoModel
[2023-12-13 13:21:21,757][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:21:21,768][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:21:21,776][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:21:21,777][dataset][INFO] - Using tokenizer
[2023-12-13 13:21:21,920][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:21:21,921][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f8b4268a5e0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:21:21,936][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:21:21,936][dataset][INFO] - Using tokenizer
[2023-12-13 13:21:21,941][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:21:21,942][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f8b42686100>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:21:21,945][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:21:22,710][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:21:22,710][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:21:22,711][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:21:22,711][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:21:22,711][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:21:22,712][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:21:22,712][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:22:39,971][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:22:40,740][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:22:41,817][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:22:42,333][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:22:42,338][main][INFO] - model: AudioVideoModel
[2023-12-13 13:22:42,339][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:22:42,350][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:22:42,358][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:22:42,358][dataset][INFO] - Using tokenizer
[2023-12-13 13:22:42,503][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:22:42,504][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f88c274b490>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:22:42,520][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:22:42,520][dataset][INFO] - Using tokenizer
[2023-12-13 13:22:42,525][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:22:42,525][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f88c2748be0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:22:42,529][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:22:42,819][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:22:42,819][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:22:42,819][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:22:42,819][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:22:42,820][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:22:42,821][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:22:42,821][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:32:43,049][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:32:43,792][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:32:44,862][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:32:45,377][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:32:45,382][main][INFO] - model: AudioVideoModel
[2023-12-13 13:32:45,382][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:32:45,394][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:32:45,401][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:32:45,402][dataset][INFO] - Using tokenizer
[2023-12-13 13:32:45,560][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:32:45,561][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7ff63b14c460>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:32:45,577][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:32:45,577][dataset][INFO] - Using tokenizer
[2023-12-13 13:32:45,582][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:32:45,583][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7ff63b149bb0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:32:45,586][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:32:45,902][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:32:45,903][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:32:45,903][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:32:45,903][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:32:45,903][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:32:45,904][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:32:45,905][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:44:03,836][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:44:04,524][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:44:05,593][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:44:06,100][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:44:06,105][main][INFO] - model: AudioVideoModel
[2023-12-13 13:44:06,105][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:44:06,116][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:44:06,124][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:44:06,124][dataset][INFO] - Using tokenizer
[2023-12-13 13:44:06,278][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:44:06,279][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f205efcc4c0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:44:06,294][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:44:06,295][dataset][INFO] - Using tokenizer
[2023-12-13 13:44:06,300][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:44:06,300][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f205efc9c10>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:44:06,303][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:44:06,619][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:44:06,619][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:44:06,619][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:44:06,619][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:44:06,619][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:44:06,620][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:44:06,621][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:44:15,661][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:44:16,344][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:44:17,409][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:44:17,910][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:44:17,915][main][INFO] - model: AudioVideoModel
[2023-12-13 13:44:17,915][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:44:17,926][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:44:17,934][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:44:17,935][dataset][INFO] - Using tokenizer
[2023-12-13 13:44:18,076][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:44:18,077][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7fdce2b4b5b0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:44:18,092][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:44:18,093][dataset][INFO] - Using tokenizer
[2023-12-13 13:44:18,098][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:44:18,098][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7fdce2b47f10>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:44:18,102][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:44:18,414][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:44:18,415][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:44:18,415][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:44:18,415][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:44:18,415][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:44:18,416][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:44:18,416][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:45:09,519][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:45:10,257][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:45:11,325][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:45:11,819][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:45:11,824][main][INFO] - model: AudioVideoModel
[2023-12-13 13:45:11,824][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:45:11,835][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:45:11,842][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:45:11,843][dataset][INFO] - Using tokenizer
[2023-12-13 13:45:11,991][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:45:11,992][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f30df351f10>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:45:12,008][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:45:12,008][dataset][INFO] - Using tokenizer
[2023-12-13 13:45:12,013][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:45:12,013][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f30df351b50>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:45:12,017][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:45:12,246][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:45:12,246][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:45:12,246][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:45:12,247][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:45:12,247][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:45:12,248][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:45:12,248][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:46:04,704][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:46:05,450][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:46:06,673][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:46:07,174][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:46:07,179][main][INFO] - model: AudioVideoModel
[2023-12-13 13:46:07,179][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:46:07,191][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:46:07,198][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:46:07,199][dataset][INFO] - Using tokenizer
[2023-12-13 13:46:07,345][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:46:07,346][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f646cf497c0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:46:07,362][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:46:07,362][dataset][INFO] - Using tokenizer
[2023-12-13 13:46:07,367][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:46:07,367][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f646cf49310>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:46:07,371][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:46:07,678][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:46:07,678][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:46:07,679][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:46:07,679][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:46:07,679][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:46:07,680][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:46:07,681][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:48:13,060][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:48:13,750][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:48:14,822][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:48:15,400][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:48:15,405][main][INFO] - model: AudioVideoModel
[2023-12-13 13:48:15,405][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:48:15,416][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:48:15,424][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:48:15,424][dataset][INFO] - Using tokenizer
[2023-12-13 13:48:15,497][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:48:15,498][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7fbb87991340>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:48:15,513][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:48:15,514][dataset][INFO] - Using tokenizer
[2023-12-13 13:48:15,519][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:48:15,519][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7fbb879a2700>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:48:15,523][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:48:15,968][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:48:15,968][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:48:15,968][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:48:15,969][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:48:15,969][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:48:15,970][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:48:15,970][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 13:52:51,820][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 13:52:52,506][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 13:52:53,540][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 13:52:54,046][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 13:52:54,051][main][INFO] - model: AudioVideoModel
[2023-12-13 13:52:54,051][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 13:52:54,063][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 13:52:54,070][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 13:52:54,071][dataset][INFO] - Using tokenizer
[2023-12-13 13:52:54,206][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 13:52:54,207][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7fded894c3d0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:52:54,222][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:52:54,223][dataset][INFO] - Using tokenizer
[2023-12-13 13:52:54,228][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 13:52:54,228][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7fded8949580>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 13:52:54,232][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 13:52:54,523][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:52:54,523][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 13:52:54,523][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 13:52:54,523][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 13:52:54,523][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 13:52:54,524][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 13:52:54,525][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 14:22:26,024][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 14:22:26,778][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 14:22:27,882][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 14:22:28,393][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 14:22:28,398][main][INFO] - model: AudioVideoModel
[2023-12-13 14:22:28,398][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 14:22:28,409][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 14:22:28,417][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 14:22:28,417][dataset][INFO] - Using tokenizer
[2023-12-13 14:22:28,590][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 14:22:28,592][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7fe731a40730>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 14:22:28,607][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 14:22:28,608][dataset][INFO] - Using tokenizer
[2023-12-13 14:22:28,613][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 14:22:28,613][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7fe731a400a0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 14:22:28,617][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 14:22:29,013][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 14:22:29,014][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 14:22:29,014][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 14:22:29,014][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 14:22:29,014][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 14:22:29,015][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 14:22:29,015][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 14:48:15,356][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 14:48:16,092][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 14:48:17,136][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 14:48:17,644][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 14:48:17,649][main][INFO] - model: AudioVideoModel
[2023-12-13 14:48:17,649][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 14:48:17,660][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 14:48:17,668][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 14:48:17,668][dataset][INFO] - Using tokenizer
[2023-12-13 14:48:17,818][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 14:48:17,820][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f6eb7d4c550>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 14:48:17,835][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 14:48:17,835][dataset][INFO] - Using tokenizer
[2023-12-13 14:48:17,840][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 14:48:17,841][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f6eb7d489d0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 14:48:17,844][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 14:48:18,164][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 14:48:18,164][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 14:48:18,164][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 14:48:18,164][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 14:48:18,165][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 14:48:18,166][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 14:48:18,166][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 14:57:12,253][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 14:57:13,005][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 14:57:14,092][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 14:57:14,608][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 14:57:14,613][main][INFO] - model: AudioVideoModel
[2023-12-13 14:57:14,613][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 14:57:14,624][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 14:57:14,632][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 14:57:14,632][dataset][INFO] - Using tokenizer
[2023-12-13 14:57:14,813][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 14:57:14,814][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f75d5686490>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 14:57:14,829][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 14:57:14,830][dataset][INFO] - Using tokenizer
[2023-12-13 14:57:14,835][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 14:57:14,835][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f75d5682c10>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 14:57:14,839][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 14:57:15,288][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 14:57:15,288][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 14:57:15,288][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 14:57:15,288][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 14:57:15,289][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 14:57:15,290][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 14:57:15,290][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 15:29:02,814][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 15:29:03,574][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 15:29:04,618][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 15:29:05,152][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 15:29:05,158][main][INFO] - model: AudioVideoModel
[2023-12-13 15:29:05,158][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 15:29:05,169][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 15:29:05,177][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 15:29:05,177][dataset][INFO] - Using tokenizer
[2023-12-13 15:29:05,324][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 15:29:05,326][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f6de35788b0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 15:29:05,341][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 15:29:05,341][dataset][INFO] - Using tokenizer
[2023-12-13 15:29:05,346][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 15:29:05,347][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f6de3578490>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 15:29:05,350][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 15:29:06,147][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 15:29:06,147][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 15:29:06,147][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 15:29:06,147][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 15:29:06,148][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 15:29:06,149][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 15:29:06,149][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 15:41:28,179][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 15:41:29,421][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 15:41:34,205][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 15:41:35,402][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 15:41:35,412][main][INFO] - model: AudioVideoModel
[2023-12-13 15:41:35,413][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 15:41:35,428][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 15:41:35,437][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 15:41:35,437][dataset][INFO] - Using tokenizer
[2023-12-13 15:41:35,680][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 15:41:35,684][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f12f794c4c0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 15:41:35,717][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 15:41:35,719][dataset][INFO] - Using tokenizer
[2023-12-13 15:41:35,728][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 15:41:35,729][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f12f7949d00>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 15:41:35,735][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 15:41:40,677][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 15:41:40,678][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 15:41:40,678][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 15:41:40,678][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 15:41:40,679][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 15:41:40,681][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 15:41:40,681][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 15:42:39,142][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 15:42:40,474][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 15:42:45,653][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 15:42:47,000][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 15:42:47,013][main][INFO] - model: AudioVideoModel
[2023-12-13 15:42:47,028][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 15:42:47,055][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 15:42:47,066][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 15:42:47,067][dataset][INFO] - Using tokenizer
[2023-12-13 15:42:47,537][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 15:42:47,542][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f2a4670c430>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 15:42:47,575][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 15:42:47,576][dataset][INFO] - Using tokenizer
[2023-12-13 15:42:47,588][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 15:42:47,589][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f2a46708b80>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 15:42:47,595][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 15:42:54,353][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 15:42:54,354][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 15:42:54,354][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 15:42:54,355][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 15:42:54,355][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 15:42:54,357][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 15:42:54,384][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 15:45:13,833][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 15:45:15,586][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 15:45:21,124][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 15:45:22,795][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 15:45:22,805][main][INFO] - model: AudioVideoModel
[2023-12-13 15:45:22,805][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 15:45:22,857][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 15:45:22,887][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 15:45:22,895][dataset][INFO] - Using tokenizer
[2023-12-13 15:45:23,184][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 15:45:23,187][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f78feb78850>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 15:45:23,220][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 15:45:23,221][dataset][INFO] - Using tokenizer
[2023-12-13 15:45:23,231][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 15:45:23,233][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f78feb784c0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 15:45:23,239][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 15:45:30,105][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 15:45:30,106][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 15:45:30,106][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 15:45:30,107][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 15:45:30,108][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 15:45:30,110][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 15:45:30,110][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 16:27:59,933][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 16:28:01,393][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 16:28:06,202][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 16:28:07,899][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 16:28:07,923][main][INFO] - model: AudioVideoModel
[2023-12-13 16:28:07,924][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 16:28:07,966][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 16:28:07,985][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 16:28:07,996][dataset][INFO] - Using tokenizer
[2023-12-13 16:28:08,381][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 16:28:08,384][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f335cecb460>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 16:28:08,415][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 16:28:08,417][dataset][INFO] - Using tokenizer
[2023-12-13 16:28:08,426][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 16:28:08,427][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f335cf5cbb0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 16:28:08,435][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 16:28:13,038][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 16:28:13,039][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 16:28:13,039][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 16:28:13,039][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 16:28:13,040][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 16:28:13,042][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 16:28:13,042][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 16:31:28,184][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 16:31:30,213][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 16:31:36,946][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 16:31:38,473][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 16:31:38,482][main][INFO] - model: AudioVideoModel
[2023-12-13 16:31:38,483][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 16:31:38,518][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 16:31:38,538][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 16:31:38,539][dataset][INFO] - Using tokenizer
[2023-12-13 16:31:38,979][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 16:31:38,981][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7fcd8ea10430>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 16:31:39,054][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 16:31:39,064][dataset][INFO] - Using tokenizer
[2023-12-13 16:31:39,102][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 16:31:39,105][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7fcd8ea0db80>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 16:31:39,112][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 16:31:43,197][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 16:31:43,212][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 16:31:43,213][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 16:31:43,214][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 16:31:43,217][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 16:31:43,220][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 16:31:43,224][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 16:34:12,945][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 16:34:14,535][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 16:34:19,117][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 16:34:20,846][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 16:34:20,856][main][INFO] - model: AudioVideoModel
[2023-12-13 16:34:20,856][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 16:34:20,880][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 16:34:20,895][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 16:34:20,897][dataset][INFO] - Using tokenizer
[2023-12-13 16:34:21,463][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 16:34:21,466][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7fb535acd370>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 16:34:21,535][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 16:34:21,536][dataset][INFO] - Using tokenizer
[2023-12-13 16:34:21,544][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 16:34:21,545][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7fb535acbe80>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 16:34:21,549][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 16:34:29,857][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 16:34:29,857][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 16:34:29,858][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 16:34:29,859][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 16:34:29,859][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 16:34:29,861][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 16:34:29,863][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 17:15:16,000][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 17:15:17,381][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 17:15:23,181][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 17:15:24,535][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 17:15:24,551][main][INFO] - model: AudioVideoModel
[2023-12-13 17:15:24,551][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 17:15:24,575][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 17:15:24,589][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 17:15:24,590][dataset][INFO] - Using tokenizer
[2023-12-13 17:15:24,848][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 17:15:24,851][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f5591f4b3a0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:15:24,876][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:15:24,877][dataset][INFO] - Using tokenizer
[2023-12-13 17:15:24,886][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 17:15:24,887][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f5591f49490>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:15:24,895][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:17:09,741][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 17:17:11,704][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 17:17:17,732][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 17:17:19,313][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 17:17:19,319][main][INFO] - model: AudioVideoModel
[2023-12-13 17:17:19,320][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 17:17:19,335][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 17:17:19,350][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 17:17:19,351][dataset][INFO] - Using tokenizer
[2023-12-13 17:17:19,702][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 17:17:19,704][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f9fde827070>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:17:19,736][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:17:19,737][dataset][INFO] - Using tokenizer
[2023-12-13 17:17:19,747][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 17:17:19,748][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f9fde81e460>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:17:19,756][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:17:49,723][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:17:49,736][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 17:17:49,736][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:17:49,737][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 17:18:19,865][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 17:18:29,215][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 17:18:29,216][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 17:19:50,978][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 17:19:52,125][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 17:19:57,855][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 17:19:59,070][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 17:19:59,085][main][INFO] - model: AudioVideoModel
[2023-12-13 17:19:59,085][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 17:19:59,107][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 17:19:59,123][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 17:19:59,123][dataset][INFO] - Using tokenizer
[2023-12-13 17:19:59,444][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 17:19:59,446][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f9b922cb4c0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:19:59,485][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:19:59,486][dataset][INFO] - Using tokenizer
[2023-12-13 17:19:59,495][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 17:19:59,496][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f9b92374c40>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:19:59,502][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:20:03,964][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:20:03,965][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 17:20:03,965][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:20:03,966][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 17:20:03,966][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 17:20:45,039][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 17:20:45,040][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 17:24:16,072][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 17:24:17,707][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 17:24:23,045][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 17:24:24,533][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 17:24:24,552][main][INFO] - model: AudioVideoModel
[2023-12-13 17:24:24,553][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 17:24:24,575][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 17:24:24,589][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 17:24:24,590][dataset][INFO] - Using tokenizer
[2023-12-13 17:24:24,842][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 17:24:24,845][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f78122d40d0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:24:24,914][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:24:24,916][dataset][INFO] - Using tokenizer
[2023-12-13 17:24:24,925][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 17:24:24,926][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f78122cac40>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:24:24,932][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:24:32,572][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:24:32,572][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 17:24:32,573][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:24:32,573][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 17:24:32,574][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 17:26:34,590][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 17:26:34,593][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 17:31:05,382][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 17:31:06,691][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 17:31:10,569][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 17:31:11,490][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 17:31:11,509][main][INFO] - model: AudioVideoModel
[2023-12-13 17:31:11,509][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 17:31:11,539][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 17:31:11,555][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 17:31:11,555][dataset][INFO] - Using tokenizer
[2023-12-13 17:31:11,988][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 17:31:12,024][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f8c7470c700>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:31:12,065][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:31:12,066][dataset][INFO] - Using tokenizer
[2023-12-13 17:31:12,074][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 17:31:12,075][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f8c7470c0a0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:31:12,081][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:31:17,977][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:31:17,978][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 17:31:17,978][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:31:17,978][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 17:31:17,979][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 17:31:31,735][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 17:31:31,735][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 17:35:30,555][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 17:35:31,603][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 17:35:35,309][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 17:35:36,464][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 17:35:36,474][main][INFO] - model: AudioVideoModel
[2023-12-13 17:35:36,474][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 17:35:36,505][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 17:35:36,521][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 17:35:36,522][dataset][INFO] - Using tokenizer
[2023-12-13 17:35:36,814][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 17:35:36,816][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7fc5b12cb790>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:35:36,855][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:35:36,856][dataset][INFO] - Using tokenizer
[2023-12-13 17:35:36,866][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 17:35:36,866][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7fc5b12cb100>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:35:36,873][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:35:40,457][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:35:40,457][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 17:35:40,457][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:35:40,458][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 17:35:40,459][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 17:38:39,919][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 17:38:39,920][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 17:42:21,699][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 17:42:22,966][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 17:42:28,661][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 17:42:30,058][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 17:42:30,076][main][INFO] - model: AudioVideoModel
[2023-12-13 17:42:30,077][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 17:42:30,106][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 17:42:30,124][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 17:42:30,125][dataset][INFO] - Using tokenizer
[2023-12-13 17:42:30,447][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 17:42:30,452][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f15040cb760>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:42:30,487][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:42:30,488][dataset][INFO] - Using tokenizer
[2023-12-13 17:42:30,507][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 17:42:30,517][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f15040cb100>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:42:30,528][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:42:35,548][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:42:35,548][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 17:42:35,549][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:42:35,550][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 17:42:35,550][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 17:43:06,979][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 17:43:06,980][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 17:50:53,253][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 17:50:54,341][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 17:50:58,716][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 17:50:59,855][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 17:50:59,865][main][INFO] - model: AudioVideoModel
[2023-12-13 17:50:59,865][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 17:50:59,932][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 17:51:00,069][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 17:51:00,070][dataset][INFO] - Using tokenizer
[2023-12-13 17:51:00,294][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 17:51:00,296][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f4f530c76d0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:51:00,327][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:51:00,328][dataset][INFO] - Using tokenizer
[2023-12-13 17:51:00,337][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 17:51:00,338][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f4f530c7100>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:51:00,345][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:51:05,053][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:51:05,055][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 17:51:05,056][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:51:05,056][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 17:51:05,057][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 17:51:14,556][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 17:51:14,557][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 17:52:44,658][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 17:52:46,062][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 17:52:50,848][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 17:52:52,084][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 17:52:52,097][main][INFO] - model: AudioVideoModel
[2023-12-13 17:52:52,098][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 17:52:52,198][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 17:52:52,254][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 17:52:52,255][dataset][INFO] - Using tokenizer
[2023-12-13 17:52:52,485][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 17:52:52,488][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f80aa8c7790>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:52:52,518][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:52:52,520][dataset][INFO] - Using tokenizer
[2023-12-13 17:52:52,529][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 17:52:52,530][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f80aa8c71f0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 17:52:52,537][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 17:52:58,223][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:52:58,223][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 17:52:58,223][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 17:52:58,224][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 17:52:58,224][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 17:53:49,046][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 17:53:49,047][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 18:03:36,287][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 18:03:37,236][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 18:03:41,977][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 18:03:43,329][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 18:03:43,338][main][INFO] - model: AudioVideoModel
[2023-12-13 18:03:43,338][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 18:03:43,383][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 18:03:43,421][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 18:03:43,422][dataset][INFO] - Using tokenizer
[2023-12-13 18:03:43,609][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 18:03:43,610][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7fc2f3f476d0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 18:03:43,635][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 18:03:43,636][dataset][INFO] - Using tokenizer
[2023-12-13 18:03:43,643][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 18:03:43,643][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7fc2f3f47100>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 18:03:43,649][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 18:03:49,327][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 18:03:49,328][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 18:03:49,328][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 18:03:49,337][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 18:03:49,338][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 18:04:01,463][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 18:04:01,463][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 18:06:16,300][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 18:06:18,038][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 18:06:24,809][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 18:06:26,460][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 18:06:26,479][main][INFO] - model: AudioVideoModel
[2023-12-13 18:06:26,479][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 18:06:26,571][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 18:06:26,635][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 18:06:26,652][dataset][INFO] - Using tokenizer
[2023-12-13 18:06:27,254][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 18:06:27,257][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f677aa19af0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 18:06:27,366][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 18:06:27,379][dataset][INFO] - Using tokenizer
[2023-12-13 18:06:27,403][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 18:06:27,404][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f677aa19430>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 18:06:27,409][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 18:06:34,846][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 18:06:34,846][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 18:06:34,847][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 18:06:34,847][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 18:06:34,848][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 18:06:47,534][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 18:06:47,535][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 18:08:06,675][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 18:08:08,146][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 18:08:14,315][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 18:08:15,681][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 18:08:15,692][main][INFO] - model: AudioVideoModel
[2023-12-13 18:08:15,692][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 18:08:15,789][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 18:08:15,841][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 18:08:15,842][dataset][INFO] - Using tokenizer
[2023-12-13 18:08:16,084][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 18:08:16,086][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f16038c8730>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 18:08:16,115][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 18:08:16,116][dataset][INFO] - Using tokenizer
[2023-12-13 18:08:16,125][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 18:08:16,126][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f16038c80a0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 18:08:16,134][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 18:08:25,800][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 18:08:25,800][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 18:08:25,801][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 18:08:25,801][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 18:08:25,802][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 18:08:25,804][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 18:08:25,805][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 18:10:49,158][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 18:10:50,190][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 18:10:55,182][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 18:10:55,992][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 18:10:55,998][main][INFO] - model: AudioVideoModel
[2023-12-13 18:10:55,998][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 18:10:56,039][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 18:10:56,067][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 18:10:56,068][dataset][INFO] - Using tokenizer
[2023-12-13 18:10:56,233][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 18:10:56,234][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f687b8c7400>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 18:10:56,251][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 18:10:56,252][dataset][INFO] - Using tokenizer
[2023-12-13 18:10:56,256][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 18:10:56,257][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f687b8c1b20>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 18:10:56,261][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 18:11:01,708][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 18:11:01,709][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 18:11:01,709][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 18:11:01,709][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 18:11:01,710][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 18:11:01,711][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 18:11:01,711][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 19:40:47,154][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 19:40:49,244][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 19:41:26,991][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight'])
[2023-12-13 19:41:28,250][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer4): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 19:41:28,265][main][INFO] - model: AudioVideoModel
[2023-12-13 19:41:28,265][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 19:41:28,377][main][INFO] - num. shared model params: 160,016,000 (num. trained: 160,016,000)
[2023-12-13 19:41:28,451][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 19:41:28,452][dataset][INFO] - Using tokenizer
[2023-12-13 19:41:28,718][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 19:41:28,721][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f19febca310>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 19:41:28,754][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 19:41:28,755][dataset][INFO] - Using tokenizer
[2023-12-13 19:41:28,766][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 19:41:28,767][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f19febc38b0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 19:41:28,776][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 19:41:36,024][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv1.bias
[2023-12-13 19:41:36,025][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv2.bias
[2023-12-13 19:41:36,025][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv1.bias
[2023-12-13 19:41:36,025][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv2.bias
[2023-12-13 19:41:36,025][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv1.bias
[2023-12-13 19:41:36,026][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv2.bias
[2023-12-13 19:41:36,026][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.downsample.0.bias
[2023-12-13 19:41:36,026][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv1.bias
[2023-12-13 19:41:36,026][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv2.bias
[2023-12-13 19:41:36,026][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv1.bias
[2023-12-13 19:41:36,026][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv2.bias
[2023-12-13 19:41:36,027][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.downsample.0.bias
[2023-12-13 19:41:36,027][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv1.bias
[2023-12-13 19:41:36,027][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv2.bias
[2023-12-13 19:41:36,027][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv1.bias
[2023-12-13 19:41:36,028][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv2.bias
[2023-12-13 19:41:36,028][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.downsample.0.bias
[2023-12-13 19:41:36,028][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv1.bias
[2023-12-13 19:41:36,028][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv2.bias
[2023-12-13 19:41:36,029][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 19:41:36,029][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 19:41:36,030][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 19:41:36,030][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 19:41:36,031][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 19:41:36,033][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 19:41:36,033][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 19:46:34,421][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 19:46:35,564][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 19:46:42,107][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight'])
[2023-12-13 19:46:43,321][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer4): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 19:46:43,332][main][INFO] - model: AudioVideoModel
[2023-12-13 19:46:43,332][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 19:46:43,404][main][INFO] - num. shared model params: 160,016,000 (num. trained: 160,016,000)
[2023-12-13 19:46:43,477][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 19:46:43,485][dataset][INFO] - Using tokenizer
[2023-12-13 19:46:43,817][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 19:46:43,819][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f6b184c81c0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 19:46:43,852][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 19:46:43,853][dataset][INFO] - Using tokenizer
[2023-12-13 19:46:43,862][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 19:46:43,863][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f6b184c2d90>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 19:46:43,871][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 19:46:51,193][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv1.bias
[2023-12-13 19:46:51,194][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv2.bias
[2023-12-13 19:46:51,194][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv1.bias
[2023-12-13 19:46:51,194][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv2.bias
[2023-12-13 19:46:51,194][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv1.bias
[2023-12-13 19:46:51,195][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv2.bias
[2023-12-13 19:46:51,195][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.downsample.0.bias
[2023-12-13 19:46:51,195][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv1.bias
[2023-12-13 19:46:51,195][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv2.bias
[2023-12-13 19:46:51,195][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv1.bias
[2023-12-13 19:46:51,196][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv2.bias
[2023-12-13 19:46:51,202][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.downsample.0.bias
[2023-12-13 19:46:51,202][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv1.bias
[2023-12-13 19:46:51,203][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv2.bias
[2023-12-13 19:46:51,203][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv1.bias
[2023-12-13 19:46:51,204][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv2.bias
[2023-12-13 19:46:51,204][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.downsample.0.bias
[2023-12-13 19:46:51,205][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv1.bias
[2023-12-13 19:46:51,205][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv2.bias
[2023-12-13 19:46:51,207][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 19:46:51,208][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 19:46:51,208][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 19:46:51,209][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 19:46:51,210][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 19:47:57,162][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 19:47:57,163][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 19:49:22,019][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 19:49:23,259][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 19:49:29,331][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 19:49:30,542][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 19:49:30,555][main][INFO] - model: AudioVideoModel
[2023-12-13 19:49:30,555][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 19:49:30,674][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 19:49:30,751][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 19:49:30,780][dataset][INFO] - Using tokenizer
[2023-12-13 19:49:31,156][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 19:49:31,159][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7fe7045c93d0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 19:49:31,298][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 19:49:31,325][dataset][INFO] - Using tokenizer
[2023-12-13 19:49:31,343][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 19:49:31,349][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7fe7045c3ee0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 19:49:31,358][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 19:49:38,394][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 19:49:38,395][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 19:49:38,395][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 19:49:38,396][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 19:49:38,396][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 19:51:11,024][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 19:51:12,187][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 19:51:19,197][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight'])
[2023-12-13 19:51:20,317][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer4): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 19:51:20,337][main][INFO] - model: AudioVideoModel
[2023-12-13 19:51:20,338][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 19:51:20,514][main][INFO] - num. shared model params: 160,016,000 (num. trained: 160,016,000)
[2023-12-13 19:51:20,576][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 19:51:20,585][dataset][INFO] - Using tokenizer
[2023-12-13 19:51:20,991][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 19:51:20,993][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f0376cc7250>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 19:51:21,034][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 19:51:21,039][dataset][INFO] - Using tokenizer
[2023-12-13 19:51:21,054][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 19:51:21,062][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f0376cc2e50>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 19:51:21,073][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 19:51:30,563][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv1.bias
[2023-12-13 19:51:30,564][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv2.bias
[2023-12-13 19:51:30,564][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv1.bias
[2023-12-13 19:51:30,564][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv2.bias
[2023-12-13 19:51:30,564][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv1.bias
[2023-12-13 19:51:30,565][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv2.bias
[2023-12-13 19:51:30,565][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.downsample.0.bias
[2023-12-13 19:51:30,565][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv1.bias
[2023-12-13 19:51:30,565][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv2.bias
[2023-12-13 19:51:30,565][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv1.bias
[2023-12-13 19:51:30,565][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv2.bias
[2023-12-13 19:51:30,566][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.downsample.0.bias
[2023-12-13 19:51:30,566][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv1.bias
[2023-12-13 19:51:30,566][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv2.bias
[2023-12-13 19:51:30,566][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv1.bias
[2023-12-13 19:51:30,566][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv2.bias
[2023-12-13 19:51:30,567][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.downsample.0.bias
[2023-12-13 19:51:30,567][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv1.bias
[2023-12-13 19:51:30,567][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv2.bias
[2023-12-13 19:51:30,568][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 19:51:30,568][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 19:51:30,568][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 19:51:30,569][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 19:51:30,569][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 19:53:54,941][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 19:53:54,942][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 20:01:17,783][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 20:01:18,843][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 20:01:23,352][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight'])
[2023-12-13 20:01:24,233][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer4): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 20:01:24,252][main][INFO] - model: AudioVideoModel
[2023-12-13 20:01:24,252][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 20:01:24,325][main][INFO] - num. shared model params: 160,016,000 (num. trained: 160,016,000)
[2023-12-13 20:01:24,389][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 20:01:24,390][dataset][INFO] - Using tokenizer
[2023-12-13 20:01:24,656][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 20:01:24,658][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f1d6f2c6220>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:01:24,676][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:01:24,676][dataset][INFO] - Using tokenizer
[2023-12-13 20:01:24,683][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 20:01:24,683][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f1d6f2c1c40>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:01:24,689][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:01:30,764][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv1.bias
[2023-12-13 20:01:30,765][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv2.bias
[2023-12-13 20:01:30,766][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv1.bias
[2023-12-13 20:01:30,766][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv2.bias
[2023-12-13 20:01:30,766][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv1.bias
[2023-12-13 20:01:30,766][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv2.bias
[2023-12-13 20:01:30,767][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.downsample.0.bias
[2023-12-13 20:01:30,767][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv1.bias
[2023-12-13 20:01:30,767][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv2.bias
[2023-12-13 20:01:30,767][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv1.bias
[2023-12-13 20:01:30,767][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv2.bias
[2023-12-13 20:01:30,768][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.downsample.0.bias
[2023-12-13 20:01:30,768][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv1.bias
[2023-12-13 20:01:30,768][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv2.bias
[2023-12-13 20:01:30,768][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv1.bias
[2023-12-13 20:01:30,768][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv2.bias
[2023-12-13 20:01:30,768][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.downsample.0.bias
[2023-12-13 20:01:30,768][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv1.bias
[2023-12-13 20:01:30,769][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv2.bias
[2023-12-13 20:01:30,769][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:01:30,770][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 20:01:30,770][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:01:30,770][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 20:01:30,771][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 20:01:52,468][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 20:01:52,469][trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-12-13 20:03:17,355][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 20:03:18,326][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 20:03:22,459][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight'])
[2023-12-13 20:03:23,691][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer4): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 20:03:23,703][main][INFO] - model: AudioVideoModel
[2023-12-13 20:03:23,703][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 20:03:23,770][main][INFO] - num. shared model params: 160,016,000 (num. trained: 160,016,000)
[2023-12-13 20:03:23,832][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 20:03:23,833][dataset][INFO] - Using tokenizer
[2023-12-13 20:03:24,014][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 20:03:24,016][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f0ba56c6220>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:03:24,045][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:03:24,046][dataset][INFO] - Using tokenizer
[2023-12-13 20:03:24,055][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 20:03:24,056][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f0ba56c1e20>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:03:24,064][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:03:28,693][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv1.bias
[2023-12-13 20:03:28,694][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv2.bias
[2023-12-13 20:03:28,694][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv1.bias
[2023-12-13 20:03:28,694][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv2.bias
[2023-12-13 20:03:28,695][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv1.bias
[2023-12-13 20:03:28,695][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv2.bias
[2023-12-13 20:03:28,695][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.downsample.0.bias
[2023-12-13 20:03:28,695][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv1.bias
[2023-12-13 20:03:28,695][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv2.bias
[2023-12-13 20:03:28,695][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv1.bias
[2023-12-13 20:03:28,696][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv2.bias
[2023-12-13 20:03:28,696][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.downsample.0.bias
[2023-12-13 20:03:28,696][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv1.bias
[2023-12-13 20:03:28,696][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv2.bias
[2023-12-13 20:03:28,696][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv1.bias
[2023-12-13 20:03:28,697][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv2.bias
[2023-12-13 20:03:28,697][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.downsample.0.bias
[2023-12-13 20:03:28,697][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv1.bias
[2023-12-13 20:03:28,697][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv2.bias
[2023-12-13 20:03:28,698][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:03:28,698][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 20:03:28,698][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:03:28,699][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 20:03:28,699][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 20:03:33,613][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 20:16:14,151][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 20:16:15,449][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 20:16:22,623][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight'])
[2023-12-13 20:16:24,145][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer4): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 20:16:24,164][main][INFO] - model: AudioVideoModel
[2023-12-13 20:16:24,164][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 20:16:24,316][main][INFO] - num. shared model params: 160,016,000 (num. trained: 160,016,000)
[2023-12-13 20:16:24,471][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 20:16:24,472][dataset][INFO] - Using tokenizer
[2023-12-13 20:16:25,026][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 20:16:25,028][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f4e3d7c88b0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:16:25,059][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:16:25,060][dataset][INFO] - Using tokenizer
[2023-12-13 20:16:25,071][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 20:16:25,072][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f4e3d7c84f0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:16:25,081][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:16:32,391][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv1.bias
[2023-12-13 20:16:32,392][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv2.bias
[2023-12-13 20:16:32,392][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv1.bias
[2023-12-13 20:16:32,393][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv2.bias
[2023-12-13 20:16:32,393][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv1.bias
[2023-12-13 20:16:32,393][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv2.bias
[2023-12-13 20:16:32,394][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.downsample.0.bias
[2023-12-13 20:16:32,394][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv1.bias
[2023-12-13 20:16:32,394][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv2.bias
[2023-12-13 20:16:32,394][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv1.bias
[2023-12-13 20:16:32,394][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv2.bias
[2023-12-13 20:16:32,395][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.downsample.0.bias
[2023-12-13 20:16:32,395][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv1.bias
[2023-12-13 20:16:32,395][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv2.bias
[2023-12-13 20:16:32,395][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv1.bias
[2023-12-13 20:16:32,396][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv2.bias
[2023-12-13 20:16:32,396][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.downsample.0.bias
[2023-12-13 20:16:32,396][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv1.bias
[2023-12-13 20:16:32,396][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv2.bias
[2023-12-13 20:16:32,397][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:16:32,397][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 20:16:32,398][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:16:32,398][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 20:16:32,399][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 20:16:32,401][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 20:24:42,398][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 20:24:43,491][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 20:24:49,216][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight'])
[2023-12-13 20:24:50,310][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer4): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 20:24:50,346][main][INFO] - model: AudioVideoModel
[2023-12-13 20:24:50,352][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 20:24:50,452][main][INFO] - num. shared model params: 160,016,000 (num. trained: 160,016,000)
[2023-12-13 20:24:50,516][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 20:24:50,517][dataset][INFO] - Using tokenizer
[2023-12-13 20:24:50,758][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 20:24:50,761][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f2e1a6c7190>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:24:50,791][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:24:50,793][dataset][INFO] - Using tokenizer
[2023-12-13 20:24:50,803][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 20:24:50,804][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f2e1a6c1d90>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:24:50,813][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:24:53,708][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv1.bias
[2023-12-13 20:24:53,708][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv2.bias
[2023-12-13 20:24:53,708][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv1.bias
[2023-12-13 20:24:53,708][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv2.bias
[2023-12-13 20:24:53,708][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv1.bias
[2023-12-13 20:24:53,708][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv2.bias
[2023-12-13 20:24:53,709][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.downsample.0.bias
[2023-12-13 20:24:53,709][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv1.bias
[2023-12-13 20:24:53,709][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv2.bias
[2023-12-13 20:24:53,709][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv1.bias
[2023-12-13 20:24:53,709][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv2.bias
[2023-12-13 20:24:53,709][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.downsample.0.bias
[2023-12-13 20:24:53,709][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv1.bias
[2023-12-13 20:24:53,709][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv2.bias
[2023-12-13 20:24:53,709][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv1.bias
[2023-12-13 20:24:53,709][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv2.bias
[2023-12-13 20:24:53,710][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.downsample.0.bias
[2023-12-13 20:24:53,710][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv1.bias
[2023-12-13 20:24:53,710][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv2.bias
[2023-12-13 20:24:53,710][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:24:53,710][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 20:24:53,711][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:24:53,711][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 20:24:53,711][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 20:24:53,712][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 20:29:39,655][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 20:29:40,859][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 20:29:44,551][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight'])
[2023-12-13 20:29:45,604][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer4): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 20:29:45,617][main][INFO] - model: AudioVideoModel
[2023-12-13 20:29:45,617][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 20:29:45,669][main][INFO] - num. shared model params: 160,016,000 (num. trained: 160,016,000)
[2023-12-13 20:29:45,731][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 20:29:45,732][dataset][INFO] - Using tokenizer
[2023-12-13 20:29:46,009][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 20:29:46,011][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f7e9ef84250>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:29:46,038][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:29:46,038][dataset][INFO] - Using tokenizer
[2023-12-13 20:29:46,044][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 20:29:46,044][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f7e9effec70>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:29:46,049][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:29:52,768][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv1.bias
[2023-12-13 20:29:52,769][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv2.bias
[2023-12-13 20:29:52,769][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv1.bias
[2023-12-13 20:29:52,770][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv2.bias
[2023-12-13 20:29:52,770][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv1.bias
[2023-12-13 20:29:52,770][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv2.bias
[2023-12-13 20:29:52,771][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.downsample.0.bias
[2023-12-13 20:29:52,771][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv1.bias
[2023-12-13 20:29:52,771][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv2.bias
[2023-12-13 20:29:52,772][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv1.bias
[2023-12-13 20:29:52,772][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv2.bias
[2023-12-13 20:29:52,772][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.downsample.0.bias
[2023-12-13 20:29:52,772][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv1.bias
[2023-12-13 20:29:52,773][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv2.bias
[2023-12-13 20:29:52,774][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv1.bias
[2023-12-13 20:29:52,775][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv2.bias
[2023-12-13 20:29:52,775][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.downsample.0.bias
[2023-12-13 20:29:52,775][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv1.bias
[2023-12-13 20:29:52,776][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv2.bias
[2023-12-13 20:29:52,777][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:29:52,777][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 20:29:52,777][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:29:52,778][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 20:29:52,778][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 20:29:52,780][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 20:32:17,950][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 20:32:19,286][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 20:32:23,409][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight'])
[2023-12-13 20:32:24,382][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer4): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 20:32:24,393][main][INFO] - model: AudioVideoModel
[2023-12-13 20:32:24,393][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 20:32:24,465][main][INFO] - num. shared model params: 160,016,000 (num. trained: 160,016,000)
[2023-12-13 20:32:24,517][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 20:32:24,518][dataset][INFO] - Using tokenizer
[2023-12-13 20:32:24,780][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 20:32:24,782][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f6bffcc6310>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:32:24,812][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:32:24,813][dataset][INFO] - Using tokenizer
[2023-12-13 20:32:24,823][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 20:32:24,823][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f6bffcc0490>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:32:24,830][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:32:29,029][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv1.bias
[2023-12-13 20:32:29,030][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv2.bias
[2023-12-13 20:32:29,030][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv1.bias
[2023-12-13 20:32:29,030][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv2.bias
[2023-12-13 20:32:29,030][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv1.bias
[2023-12-13 20:32:29,030][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv2.bias
[2023-12-13 20:32:29,030][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.downsample.0.bias
[2023-12-13 20:32:29,030][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv1.bias
[2023-12-13 20:32:29,031][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv2.bias
[2023-12-13 20:32:29,031][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv1.bias
[2023-12-13 20:32:29,031][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv2.bias
[2023-12-13 20:32:29,031][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.downsample.0.bias
[2023-12-13 20:32:29,031][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv1.bias
[2023-12-13 20:32:29,031][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv2.bias
[2023-12-13 20:32:29,031][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv1.bias
[2023-12-13 20:32:29,031][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv2.bias
[2023-12-13 20:32:29,031][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.downsample.0.bias
[2023-12-13 20:32:29,032][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv1.bias
[2023-12-13 20:32:29,032][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv2.bias
[2023-12-13 20:32:29,033][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:32:29,033][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 20:32:29,033][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:32:29,033][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 20:32:29,034][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 20:32:29,035][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 20:38:20,762][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 20:38:21,691][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 20:38:25,593][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.conv1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.weight', 'feature_extractor_video.trunk.layer1.0.bn1.bias', 'feature_extractor_video.trunk.layer1.0.bn1.running_mean', 'feature_extractor_video.trunk.layer1.0.bn1.running_var', 'feature_extractor_video.trunk.layer1.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.0.conv2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.weight', 'feature_extractor_video.trunk.layer1.0.bn2.bias', 'feature_extractor_video.trunk.layer1.0.bn2.running_mean', 'feature_extractor_video.trunk.layer1.0.bn2.running_var', 'feature_extractor_video.trunk.layer1.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.conv1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.weight', 'feature_extractor_video.trunk.layer1.1.bn1.bias', 'feature_extractor_video.trunk.layer1.1.bn1.running_mean', 'feature_extractor_video.trunk.layer1.1.bn1.running_var', 'feature_extractor_video.trunk.layer1.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer1.1.conv2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.weight', 'feature_extractor_video.trunk.layer1.1.bn2.bias', 'feature_extractor_video.trunk.layer1.1.bn2.running_mean', 'feature_extractor_video.trunk.layer1.1.bn2.running_var', 'feature_extractor_video.trunk.layer1.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.conv1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.weight', 'feature_extractor_video.trunk.layer2.0.bn1.bias', 'feature_extractor_video.trunk.layer2.0.bn1.running_mean', 'feature_extractor_video.trunk.layer2.0.bn1.running_var', 'feature_extractor_video.trunk.layer2.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.0.conv2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.weight', 'feature_extractor_video.trunk.layer2.0.bn2.bias', 'feature_extractor_video.trunk.layer2.0.bn2.running_mean', 'feature_extractor_video.trunk.layer2.0.bn2.running_var', 'feature_extractor_video.trunk.layer2.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer2.0.downsample.0.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.weight', 'feature_extractor_video.trunk.layer2.0.downsample.1.bias', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer2.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer2.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.conv1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.weight', 'feature_extractor_video.trunk.layer2.1.bn1.bias', 'feature_extractor_video.trunk.layer2.1.bn1.running_mean', 'feature_extractor_video.trunk.layer2.1.bn1.running_var', 'feature_extractor_video.trunk.layer2.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer2.1.conv2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.weight', 'feature_extractor_video.trunk.layer2.1.bn2.bias', 'feature_extractor_video.trunk.layer2.1.bn2.running_mean', 'feature_extractor_video.trunk.layer2.1.bn2.running_var', 'feature_extractor_video.trunk.layer2.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.conv1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.weight', 'feature_extractor_video.trunk.layer3.0.bn1.bias', 'feature_extractor_video.trunk.layer3.0.bn1.running_mean', 'feature_extractor_video.trunk.layer3.0.bn1.running_var', 'feature_extractor_video.trunk.layer3.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.0.conv2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.weight', 'feature_extractor_video.trunk.layer3.0.bn2.bias', 'feature_extractor_video.trunk.layer3.0.bn2.running_mean', 'feature_extractor_video.trunk.layer3.0.bn2.running_var', 'feature_extractor_video.trunk.layer3.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer3.0.downsample.0.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.weight', 'feature_extractor_video.trunk.layer3.0.downsample.1.bias', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer3.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer3.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.conv1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.weight', 'feature_extractor_video.trunk.layer3.1.bn1.bias', 'feature_extractor_video.trunk.layer3.1.bn1.running_mean', 'feature_extractor_video.trunk.layer3.1.bn1.running_var', 'feature_extractor_video.trunk.layer3.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer3.1.conv2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.weight', 'feature_extractor_video.trunk.layer3.1.bn2.bias', 'feature_extractor_video.trunk.layer3.1.bn2.running_mean', 'feature_extractor_video.trunk.layer3.1.bn2.running_var', 'feature_extractor_video.trunk.layer3.1.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.conv1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.weight', 'feature_extractor_video.trunk.layer4.0.bn1.bias', 'feature_extractor_video.trunk.layer4.0.bn1.running_mean', 'feature_extractor_video.trunk.layer4.0.bn1.running_var', 'feature_extractor_video.trunk.layer4.0.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.0.conv2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.weight', 'feature_extractor_video.trunk.layer4.0.bn2.bias', 'feature_extractor_video.trunk.layer4.0.bn2.running_mean', 'feature_extractor_video.trunk.layer4.0.bn2.running_var', 'feature_extractor_video.trunk.layer4.0.bn2.num_batches_tracked', 'feature_extractor_video.trunk.layer4.0.downsample.0.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.weight', 'feature_extractor_video.trunk.layer4.0.downsample.1.bias', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_mean', 'feature_extractor_video.trunk.layer4.0.downsample.1.running_var', 'feature_extractor_video.trunk.layer4.0.downsample.1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.conv1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.weight', 'feature_extractor_video.trunk.layer4.1.bn1.bias', 'feature_extractor_video.trunk.layer4.1.bn1.running_mean', 'feature_extractor_video.trunk.layer4.1.bn1.running_var', 'feature_extractor_video.trunk.layer4.1.bn1.num_batches_tracked', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight', 'feature_extractor_video.trunk.layer4.1.conv2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.weight', 'feature_extractor_video.trunk.layer4.1.bn2.bias', 'feature_extractor_video.trunk.layer4.1.bn2.running_mean', 'feature_extractor_video.trunk.layer4.1.bn2.running_var', 'feature_extractor_video.trunk.layer4.1.bn2.num_batches_tracked'])
[2023-12-13 20:38:26,563][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential()
          (layer2): Sequential()
          (layer3): Sequential()
          (layer4): Sequential()
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 20:38:26,572][main][INFO] - model: AudioVideoModel
[2023-12-13 20:38:26,572][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 20:38:26,629][main][INFO] - num. shared model params: 148,849,024 (num. trained: 148,849,024)
[2023-12-13 20:38:26,681][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 20:38:26,682][dataset][INFO] - Using tokenizer
[2023-12-13 20:38:26,874][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 20:38:26,877][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7f985b8c4790>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:38:26,910][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:38:26,911][dataset][INFO] - Using tokenizer
[2023-12-13 20:38:26,922][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 20:38:26,923][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7f985b8c4100>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:38:26,930][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:38:29,912][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:38:29,913][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 20:38:29,913][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:38:29,914][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 20:38:29,915][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 20:38:29,917][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 20:44:29,925][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 20:44:31,098][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 20:45:28,721][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight'])
[2023-12-13 20:45:30,684][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer4): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 20:45:30,698][main][INFO] - model: AudioVideoModel
[2023-12-13 20:45:30,698][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 20:45:30,769][main][INFO] - num. shared model params: 160,016,000 (num. trained: 160,016,000)
[2023-12-13 20:45:30,830][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 20:45:30,832][dataset][INFO] - Using tokenizer
[2023-12-13 20:45:31,087][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 20:45:31,089][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7ffa156c4760>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:45:31,117][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:45:31,118][dataset][INFO] - Using tokenizer
[2023-12-13 20:45:31,129][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 20:45:31,130][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7ffa156c4100>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:45:31,139][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:46:16,420][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv1.bias
[2023-12-13 20:46:16,421][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.0.conv2.bias
[2023-12-13 20:46:16,421][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv1.bias
[2023-12-13 20:46:16,422][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer1.1.conv2.bias
[2023-12-13 20:46:16,422][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv1.bias
[2023-12-13 20:46:16,422][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.conv2.bias
[2023-12-13 20:46:16,422][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.0.downsample.0.bias
[2023-12-13 20:46:16,422][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv1.bias
[2023-12-13 20:46:16,423][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer2.1.conv2.bias
[2023-12-13 20:46:16,423][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv1.bias
[2023-12-13 20:46:16,423][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.conv2.bias
[2023-12-13 20:46:16,423][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.0.downsample.0.bias
[2023-12-13 20:46:16,424][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv1.bias
[2023-12-13 20:46:16,425][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer3.1.conv2.bias
[2023-12-13 20:46:16,425][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv1.bias
[2023-12-13 20:46:16,425][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.conv2.bias
[2023-12-13 20:46:16,425][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.0.downsample.0.bias
[2023-12-13 20:46:16,425][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv1.bias
[2023-12-13 20:46:16,426][trainer][INFO] - detected shared parameter: encoder.pretrained_model.feature_extractor_video.frontend3D.0.bias <- encoder.pretrained_model.feature_extractor_video.trunk.layer4.1.conv2.bias
[2023-12-13 20:46:16,427][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:46:16,427][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-12-13 20:46:16,427][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-12-13 20:46:16,428][main][INFO] - training on 1 devices (GPUs/TPUs)
[2023-12-13 20:48:49,555][main][INFO] - max tokens per device = 1000 and max sentences per device = None
[2023-12-13 20:49:10,097][trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-12-13 20:51:15,803][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 20:51:16,689][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 20:55:12,186][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight'])
[2023-12-13 20:55:13,762][main][INFO] - AudioVideoModel(
  (encoder): EncoderBackboneWrapper(
    (pretrained_model): EncoderBackbone(
      (feature_extractor_audio): AudioEncoder()
      (feature_extractor_video): ResEncoder(
        (frontend3D): Sequential(
          (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): PReLU(num_parameters=64)
          (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
        )
        (trunk): ResNet(
          (layer1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (layer4): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu1): ReLU(inplace=True)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu2): ReLU(inplace=True)
            )
          )
          (avgpool): AdaptiveAvgPool2d(output_size=1)
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): Dropout(p=0.0, inplace=False)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2023-12-13 20:55:13,773][main][INFO] - model: AudioVideoModel
[2023-12-13 20:55:13,774][main][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2023-12-13 20:55:13,882][main][INFO] - num. shared model params: 160,016,000 (num. trained: 160,016,000)
[2023-12-13 20:55:13,963][main][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-12-13 20:55:13,964][dataset][INFO] - Using tokenizer
[2023-12-13 20:55:14,155][dataset][INFO] - max_keep=500, min_keep=None, loaded 30782, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=12
[2023-12-13 20:55:14,158][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <utils.model_utils.HorizontalFlip object at 0x7fcd40bb68b0>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:55:14,190][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:55:14,191][dataset][INFO] - Using tokenizer
[2023-12-13 20:55:14,200][dataset][INFO] - max_keep=500, min_keep=None, loaded 1200, skipped 0 short and 0 long and 0 unaligned, longest-loaded=155, shortest-loaded=17
[2023-12-13 20:55:14,201][dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <utils.model_utils.CenterCrop object at 0x7fcd40bb6250>
    Normalize(mean=0.421, std=0.165)
)
[2023-12-13 20:55:14,208][dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2023-12-13 20:55:56,761][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 20:56:08,079][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 20:57:44,587][main][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/ai_hw_18/ly', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': c10d, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/data2/final_project_data/30h_data', 'labels': ['wrd'], 'label_dir': '/data2/final_project_data/30h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/data2/final_project_data/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}, 'model': {'_name': 'av_hubert_seq2seq', 'pretrained_path': '/data2/final_project_ckpt/pretrained_model.pth', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 30000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'report_accuracy': True, 'label_smoothing': 0.1, 'ignore_prefix_size': 0, 'sentence_avg': '${optimization.sentence_avg}'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, "use_old_adam'": False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'final_lr_scale': 0.05, 'phase_ratio': '???', 'init_lr_scale': 0.01, 'max_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None}
[2023-12-13 21:00:00,257][models.encoder_backbone][INFO] - EncoderBackbone Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2023-12-13 21:08:19,562][models.audio_video_model][INFO] - _IncompatibleKeys(missing_keys=[], unexpected_keys=['mask_emb', 'label_embs_concat', 'final_proj.weight', 'final_proj.bias', 'feature_extractor_audio.proj.weight', 'feature_extractor_audio.proj.bias', 'feature_extractor_video.trunk.layer1.0.relu1.weight', 'feature_extractor_video.trunk.layer1.0.relu2.weight', 'feature_extractor_video.trunk.layer1.1.relu1.weight', 'feature_extractor_video.trunk.layer1.1.relu2.weight', 'feature_extractor_video.trunk.layer2.0.relu1.weight', 'feature_extractor_video.trunk.layer2.0.relu2.weight', 'feature_extractor_video.trunk.layer2.1.relu1.weight', 'feature_extractor_video.trunk.layer2.1.relu2.weight', 'feature_extractor_video.trunk.layer3.0.relu1.weight', 'feature_extractor_video.trunk.layer3.0.relu2.weight', 'feature_extractor_video.trunk.layer3.1.relu1.weight', 'feature_extractor_video.trunk.layer3.1.relu2.weight', 'feature_extractor_video.trunk.layer4.0.relu1.weight', 'feature_extractor_video.trunk.layer4.0.relu2.weight', 'feature_extractor_video.trunk.layer4.1.relu1.weight', 'feature_extractor_video.trunk.layer4.1.relu2.weight'])
